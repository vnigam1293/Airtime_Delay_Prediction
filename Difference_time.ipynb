{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|IATA_CODE|             AIRLINE|\n",
      "+---------+--------------------+\n",
      "|       UA|United Air Lines ...|\n",
      "|       AA|American Airlines...|\n",
      "|       US|     US Airways Inc.|\n",
      "|       F9|Frontier Airlines...|\n",
      "|       B6|     JetBlue Airways|\n",
      "|       OO|Skywest Airlines ...|\n",
      "|       AS|Alaska Airlines Inc.|\n",
      "|       NK|    Spirit Air Lines|\n",
      "|       WN|Southwest Airline...|\n",
      "|       DL|Delta Air Lines Inc.|\n",
      "|       EV|Atlantic Southeas...|\n",
      "|       HA|Hawaiian Airlines...|\n",
      "|       MQ|American Eagle Ai...|\n",
      "|       VX|      Virgin America|\n",
      "+---------+--------------------+\n",
      "\n",
      "+---------+--------------------+-------------+-----+-------+--------+----------+\n",
      "|IATA_CODE|             AIRPORT|         CITY|STATE|COUNTRY|LATITUDE| LONGITUDE|\n",
      "+---------+--------------------+-------------+-----+-------+--------+----------+\n",
      "|      ABE|Lehigh Valley Int...|    Allentown|   PA|    USA|40.65236| -75.44040|\n",
      "|      ABI|Abilene Regional ...|      Abilene|   TX|    USA|32.41132| -99.68190|\n",
      "|      ABQ|Albuquerque Inter...|  Albuquerque|   NM|    USA|35.04022|-106.60919|\n",
      "|      ABR|Aberdeen Regional...|     Aberdeen|   SD|    USA|45.44906| -98.42183|\n",
      "|      ABY|Southwest Georgia...|       Albany|   GA|    USA|31.53552| -84.19447|\n",
      "|      ACK|Nantucket Memoria...|    Nantucket|   MA|    USA|41.25305| -70.06018|\n",
      "|      ACT|Waco Regional Air...|         Waco|   TX|    USA|31.61129| -97.23052|\n",
      "|      ACV|      Arcata Airport|Arcata/Eureka|   CA|    USA|40.97812|-124.10862|\n",
      "|      ACY|Atlantic City Int...|Atlantic City|   NJ|    USA|39.45758| -74.57717|\n",
      "|      ADK|        Adak Airport|         Adak|   AK|    USA|51.87796|-176.64603|\n",
      "|      ADQ|      Kodiak Airport|       Kodiak|   AK|    USA|57.74997|-152.49386|\n",
      "|      AEX|Alexandria Intern...|   Alexandria|   LA|    USA|31.32737| -92.54856|\n",
      "|      AGS|Augusta Regional ...|      Augusta|   GA|    USA|33.36996| -81.96450|\n",
      "|      AKN| King Salmon Airport|  King Salmon|   AK|    USA|58.67680|-156.64922|\n",
      "|      ALB|Albany Internatio...|       Albany|   NY|    USA|42.74812| -73.80298|\n",
      "|      ALO|Waterloo Regional...|     Waterloo|   IA|    USA|42.55708| -92.40034|\n",
      "|      AMA|Rick Husband Amar...|     Amarillo|   TX|    USA|35.21937|-101.70593|\n",
      "|      ANC|Ted Stevens Ancho...|    Anchorage|   AK|    USA|61.17432|-149.99619|\n",
      "|      APN|Alpena County Reg...|       Alpena|   MI|    USA|45.07807| -83.56029|\n",
      "|      ASE|Aspen-Pitkin Coun...|        Aspen|   CO|    USA|39.22316|-106.86885|\n",
      "+---------+--------------------+-------------+-----+-------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "|YEAR|MONTH|DAY|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|CANCELLATION_REASON|AIR_SYSTEM_DELAY|SECURITY_DELAY|AIRLINE_DELAY|LATE_AIRCRAFT_DELAY|WEATHER_DELAY|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "|2015|    1|  1|          4|     AS|           98|     N407AS|           ANC|                SEA|               0005|          2354|            -11|      21|      0015|           205|         194|     169|    1448|     0404|      4|             0430|        0408|          -22|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|     AA|         2336|     N3KUAA|           LAX|                PBI|               0010|          0002|             -8|      12|      0014|           280|         279|     263|    2330|     0737|      4|             0750|        0741|           -9|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|     US|          840|     N171US|           SFO|                CLT|               0020|          0018|             -2|      16|      0034|           286|         293|     266|    2296|     0800|     11|             0806|        0811|            5|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|     AA|          258|     N3HYAA|           LAX|                MIA|               0020|          0015|             -5|      15|      0030|           285|         281|     258|    2342|     0748|      8|             0805|        0756|           -9|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|     AS|          135|     N527AS|           SEA|                ANC|               0025|          0024|             -1|      11|      0035|           235|         215|     199|    1448|     0254|      5|             0320|        0259|          -21|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|     DL|          806|     N3730B|           SFO|                MSP|               0025|          0020|             -5|      18|      0038|           217|         230|     206|    1589|     0604|      6|             0602|        0610|            8|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|     NK|          612|     N635NK|           LAS|                MSP|               0025|          0019|             -6|      11|      0030|           181|         170|     154|    1299|     0504|      5|             0526|        0509|          -17|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|     US|         2013|     N584UW|           LAX|                CLT|               0030|          0044|             14|      13|      0057|           273|         249|     228|    2125|     0745|      8|             0803|        0753|          -10|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|     AA|         1112|     N3LAAA|           SFO|                DFW|               0030|          0019|            -11|      17|      0036|           195|         193|     173|    1464|     0529|      3|             0545|        0532|          -13|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|     DL|         1173|     N826DN|           LAS|                ATL|               0030|          0033|              3|      12|      0045|           221|         203|     186|    1747|     0651|      5|             0711|        0656|          -15|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|     DL|         2336|     N958DN|           DEN|                ATL|               0030|          0024|             -6|      12|      0036|           173|         149|     133|    1199|     0449|      4|             0523|        0453|          -30|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|     AA|         1674|     N853AA|           LAS|                MIA|               0035|          0027|             -8|      21|      0048|           268|         266|     238|    2174|     0746|      7|             0803|        0753|          -10|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|     DL|         1434|     N547US|           LAX|                MSP|               0035|          0035|              0|      18|      0053|           214|         210|     188|    1535|     0601|      4|             0609|        0605|           -4|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|     DL|         2324|     N3751B|           SLC|                ATL|               0040|          0034|             -6|      18|      0052|           215|         199|     176|    1590|     0548|      5|             0615|        0553|          -22|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|     DL|         2440|     N651DL|           SEA|                MSP|               0040|          0039|             -1|      28|      0107|           189|         198|     166|    1399|     0553|      4|             0549|        0557|            8|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|     AS|          108|     N309AS|           ANC|                SEA|               0045|          0041|             -4|      17|      0058|           204|         194|     173|    1448|     0451|      4|             0509|        0455|          -14|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|     DL|         1560|     N3743H|           ANC|                SEA|               0045|          0031|            -14|      25|      0056|           210|         200|     171|    1448|     0447|      4|             0515|        0451|          -24|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|     UA|         1197|     N78448|           SFO|                IAH|               0048|          0042|             -6|      11|      0053|           218|         217|     199|    1635|     0612|      7|             0626|        0619|           -7|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|     AS|          122|     N413AS|           ANC|                PDX|               0050|          0046|             -4|      11|      0057|           215|         201|     187|    1542|     0504|      3|             0525|        0507|          -18|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "|2015|    1|  1|          4|     DL|         1670|     N806DN|           PDX|                MSP|               0050|          0045|             -5|       9|      0054|           193|         186|     171|    1426|     0545|      6|             0603|        0551|          -12|       0|        0|               null|            null|          null|         null|               null|         null|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# creating dataframes\n",
    "airlines = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"airlines.csv\")\n",
    "airports = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"airports.csv\")\n",
    "flights = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"flights.csv\")\n",
    "\n",
    "# displaying and counting airlines dataset elements\n",
    "airlines.show()\n",
    "airlines.count()\n",
    "\n",
    "# displaying and counting airports dataset elements\n",
    "airports.show()\n",
    "airports.count()\n",
    "\n",
    "# displaying and counting flights dataset elements\n",
    "flights.show()\n",
    "flights.count()\n",
    "\n",
    "# calculating the column count\n",
    "len(flights.columns), flights.columns\n",
    "\n",
    "flights_df = flights.drop('CANCELLATION_REASON',\n",
    "                          'AIR_SYSTEM_DELAY',\n",
    "                          'SECURITY_DELAY',\n",
    "                          'AIRLINE_DELAY',\n",
    "                          'LATE_AIRCRAFT_DELAY',\n",
    "                          'WEATHER_DELAY')\n",
    "\n",
    "# displaying the flights dataset after removing null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"flights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31,\n",
       " ['YEAR',\n",
       "  'MONTH',\n",
       "  'DAY',\n",
       "  'DAY_OF_WEEK',\n",
       "  'AIRLINE',\n",
       "  'FLIGHT_NUMBER',\n",
       "  'TAIL_NUMBER',\n",
       "  'ORIGIN_AIRPORT',\n",
       "  'DESTINATION_AIRPORT',\n",
       "  'SCHEDULED_DEPARTURE',\n",
       "  'DEPARTURE_TIME',\n",
       "  'DEPARTURE_DELAY',\n",
       "  'TAXI_OUT',\n",
       "  'WHEELS_OFF',\n",
       "  'SCHEDULED_TIME',\n",
       "  'ELAPSED_TIME',\n",
       "  'AIR_TIME',\n",
       "  'DISTANCE',\n",
       "  'WHEELS_ON',\n",
       "  'TAXI_IN',\n",
       "  'SCHEDULED_ARRIVAL',\n",
       "  'ARRIVAL_TIME',\n",
       "  'ARRIVAL_DELAY',\n",
       "  'DIVERTED',\n",
       "  'CANCELLED',\n",
       "  'CANCELLATION_REASON',\n",
       "  'AIR_SYSTEM_DELAY',\n",
       "  'SECURITY_DELAY',\n",
       "  'AIRLINE_DELAY',\n",
       "  'LATE_AIRCRAFT_DELAY',\n",
       "  'WEATHER_DELAY'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flights.columns), flights.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- YEAR: string (nullable = true)\n",
      " |-- MONTH: string (nullable = true)\n",
      " |-- DAY: string (nullable = true)\n",
      " |-- DAY_OF_WEEK: string (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      " |-- FLIGHT_NUMBER: string (nullable = true)\n",
      " |-- TAIL_NUMBER: string (nullable = true)\n",
      " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
      " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: string (nullable = true)\n",
      " |-- DEPARTURE_TIME: string (nullable = true)\n",
      " |-- DEPARTURE_DELAY: string (nullable = true)\n",
      " |-- TAXI_OUT: string (nullable = true)\n",
      " |-- WHEELS_OFF: string (nullable = true)\n",
      " |-- SCHEDULED_TIME: string (nullable = true)\n",
      " |-- ELAPSED_TIME: string (nullable = true)\n",
      " |-- AIR_TIME: string (nullable = true)\n",
      " |-- DISTANCE: string (nullable = true)\n",
      " |-- WHEELS_ON: string (nullable = true)\n",
      " |-- TAXI_IN: string (nullable = true)\n",
      " |-- SCHEDULED_ARRIVAL: string (nullable = true)\n",
      " |-- ARRIVAL_TIME: string (nullable = true)\n",
      " |-- ARRIVAL_DELAY: string (nullable = true)\n",
      " |-- DIVERTED: string (nullable = true)\n",
      " |-- CANCELLED: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "flights_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+--------+\n",
      "|DEPARTURE_TIME|ARRIVAL_TIME|AIR_TIME|\n",
      "+--------------+------------+--------+\n",
      "|          2354|        0408|     169|\n",
      "|          0002|        0741|     263|\n",
      "|          0018|        0811|     266|\n",
      "|          0015|        0756|     258|\n",
      "|          0024|        0259|     199|\n",
      "+--------------+------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.select(\"DEPARTURE_TIME\",\"ARRIVAL_TIME\",\"AIR_TIME\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_trial = flights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as fn\n",
    "sumar = flight_trial.describe().filter(fn.col(\"summary\") == \"count\")\n",
    "plot_data = sumar.select(*((fn.lit(flight_trial.count())-fn.col(c)).alias(c) for c in flight_trial.columns)).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+\n",
      "|YEAR|MONTH|DAY|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+\n",
      "|2015|    1|  1|          4|     AS|           98|     N407AS|           ANC|                SEA|               0005|          2354|            -11|      21|      0015|           205|         194|     169|    1448|     0404|      4|             0430|        0408|          -22|       0|        0|\n",
      "|2015|    1|  1|          4|     AA|         2336|     N3KUAA|           LAX|                PBI|               0010|          0002|             -8|      12|      0014|           280|         279|     263|    2330|     0737|      4|             0750|        0741|           -9|       0|        0|\n",
      "|2015|    1|  1|          4|     US|          840|     N171US|           SFO|                CLT|               0020|          0018|             -2|      16|      0034|           286|         293|     266|    2296|     0800|     11|             0806|        0811|            5|       0|        0|\n",
      "|2015|    1|  1|          4|     AA|          258|     N3HYAA|           LAX|                MIA|               0020|          0015|             -5|      15|      0030|           285|         281|     258|    2342|     0748|      8|             0805|        0756|           -9|       0|        0|\n",
      "|2015|    1|  1|          4|     AS|          135|     N527AS|           SEA|                ANC|               0025|          0024|             -1|      11|      0035|           235|         215|     199|    1448|     0254|      5|             0320|        0259|          -21|       0|        0|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f964dd519b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import matplotlib.pylab as plt\n",
    "# #plot_data.CANCELLED > 0 \n",
    "# #love = plot_data.filter(lambda x: [plot_data[i]>0 for i in plot_data.columns ])\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# df = pd.DataFrame()\n",
    "# newdf = pd.DataFrame([plot_data[c] > 0 for c in plot_data.columns])\n",
    "# pl_dat = pd.DataFrame(np.transpose(plot_data))\n",
    "# pl_dat['polarity'] = newdf[0]\n",
    "# na_values = pl_dat.loc[pl_dat['polarity'] == True]\n",
    "# na_values.plot.bar(legend = False, title = 'NA Values')\n",
    "# #[plot_data[i]>0 for i in plot_data.columns]\n",
    "# #large_values = pd.filter(lambda y: y > 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries before removing NAs: 5819079\n",
      "NA Values:\n",
      "                        0  polarity\n",
      "TAIL_NUMBER       14721.0      True\n",
      "DEPARTURE_TIME    86153.0      True\n",
      "DEPARTURE_DELAY   86153.0      True\n",
      "TAXI_OUT          89047.0      True\n",
      "WHEELS_OFF        89047.0      True\n",
      "SCHEDULED_TIME        6.0      True\n",
      "ELAPSED_TIME     105071.0      True\n",
      "AIR_TIME         105071.0      True\n",
      "WHEELS_ON         92513.0      True\n",
      "TAXI_IN           92513.0      True\n",
      "ARRIVAL_TIME      92513.0      True\n",
      "ARRIVAL_DELAY    105071.0      True\n",
      "Number of entries before removing NAs: 0\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-----------+------------+------+\n",
      "|YEAR|MONTH|DAY|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|Cal_Airtime|Cal_Airtime1|D_TIME|\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-----------+------------+------+\n",
      "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-----------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(\"Number of entries before removing NAs:\",flights_df.count())\n",
    "# print(\"NA Values:\")\n",
    "# print(na_values)\n",
    "# print(\"Number of entries before removing NAs:\",flights_df.dropna().count())\n",
    "# Filtered_data = flights_df.dropna()\n",
    "# Filtered_data.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|DEPARTURE_TIME|\n",
      "+--------------+\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtered_data.select('DEPARTURE_TIME').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- YEAR: string (nullable = true)\n",
      " |-- MONTH: string (nullable = true)\n",
      " |-- DAY: string (nullable = true)\n",
      " |-- DAY_OF_WEEK: string (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      " |-- FLIGHT_NUMBER: string (nullable = true)\n",
      " |-- TAIL_NUMBER: string (nullable = true)\n",
      " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
      " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: string (nullable = true)\n",
      " |-- DEPARTURE_TIME: string (nullable = true)\n",
      " |-- DEPARTURE_DELAY: string (nullable = true)\n",
      " |-- TAXI_OUT: string (nullable = true)\n",
      " |-- WHEELS_OFF: string (nullable = true)\n",
      " |-- SCHEDULED_TIME: string (nullable = true)\n",
      " |-- ELAPSED_TIME: string (nullable = true)\n",
      " |-- AIR_TIME: string (nullable = true)\n",
      " |-- DISTANCE: string (nullable = true)\n",
      " |-- WHEELS_ON: string (nullable = true)\n",
      " |-- TAXI_IN: string (nullable = true)\n",
      " |-- SCHEDULED_ARRIVAL: string (nullable = true)\n",
      " |-- ARRIVAL_TIME: string (nullable = true)\n",
      " |-- ARRIVAL_DELAY: string (nullable = true)\n",
      " |-- DIVERTED: string (nullable = true)\n",
      " |-- CANCELLED: string (nullable = true)\n",
      " |-- Difference: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df=flights_df.withColumn('Difference',fn.col('ARRIVAL_TIME')-fn.col('DEPARTURE_TIME'))\n",
    "flights_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YEAR',\n",
       " 'MONTH',\n",
       " 'DAY',\n",
       " 'DAY_OF_WEEK',\n",
       " 'AIRLINE',\n",
       " 'FLIGHT_NUMBER',\n",
       " 'TAIL_NUMBER',\n",
       " 'ORIGIN_AIRPORT',\n",
       " 'DESTINATION_AIRPORT',\n",
       " 'SCHEDULED_DEPARTURE',\n",
       " 'DEPARTURE_TIME',\n",
       " 'DEPARTURE_DELAY',\n",
       " 'TAXI_OUT',\n",
       " 'WHEELS_OFF',\n",
       " 'SCHEDULED_TIME',\n",
       " 'ELAPSED_TIME',\n",
       " 'AIR_TIME',\n",
       " 'DISTANCE',\n",
       " 'WHEELS_ON',\n",
       " 'TAXI_IN',\n",
       " 'SCHEDULED_ARRIVAL',\n",
       " 'ARRIVAL_TIME',\n",
       " 'ARRIVAL_DELAY',\n",
       " 'DIVERTED',\n",
       " 'CANCELLED',\n",
       " 'Difference']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|new_dff_time|\n",
      "+------------+\n",
      "|       454.0|\n",
      "|       739.0|\n",
      "|       793.0|\n",
      "|       741.0|\n",
      "|       235.0|\n",
      "|       590.0|\n",
      "|       490.0|\n",
      "|       709.0|\n",
      "|       513.0|\n",
      "|       623.0|\n",
      "+------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- YEAR: string (nullable = true)\n",
      " |-- MONTH: string (nullable = true)\n",
      " |-- DAY: string (nullable = true)\n",
      " |-- DAY_OF_WEEK: string (nullable = true)\n",
      " |-- AIRLINE: string (nullable = true)\n",
      " |-- FLIGHT_NUMBER: string (nullable = true)\n",
      " |-- TAIL_NUMBER: string (nullable = true)\n",
      " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
      " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
      " |-- SCHEDULED_DEPARTURE: string (nullable = true)\n",
      " |-- DEPARTURE_TIME: string (nullable = true)\n",
      " |-- DEPARTURE_DELAY: string (nullable = true)\n",
      " |-- TAXI_OUT: string (nullable = true)\n",
      " |-- WHEELS_OFF: string (nullable = true)\n",
      " |-- SCHEDULED_TIME: string (nullable = true)\n",
      " |-- ELAPSED_TIME: string (nullable = true)\n",
      " |-- AIR_TIME: string (nullable = true)\n",
      " |-- DISTANCE: string (nullable = true)\n",
      " |-- WHEELS_ON: string (nullable = true)\n",
      " |-- TAXI_IN: string (nullable = true)\n",
      " |-- SCHEDULED_ARRIVAL: string (nullable = true)\n",
      " |-- ARRIVAL_TIME: string (nullable = true)\n",
      " |-- ARRIVAL_DELAY: string (nullable = true)\n",
      " |-- DIVERTED: string (nullable = true)\n",
      " |-- CANCELLED: string (nullable = true)\n",
      " |-- Difference: double (nullable = true)\n",
      " |-- new_dff_time: double (nullable = true)\n",
      " |-- Difference_Arrival: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#flights_df.select(\"Difference\").show()\n",
    "\n",
    "#Modified_diff=flights_df.select(fn.col(\"Difference\")+fn.lit(2400).alias(\"Diff\"))\n",
    "#Modified_diff.show(5)\n",
    "#flight_df=flights_df.select(fn.when(fn.col(\"Difference\")<0,))\n",
    "#DF.withColumn(\"Diff\", when((fn.col(\"Difference\")<0),lit()).otherwise(lit('T'))).show()\n",
    "flights_df=flights_df.withColumn('new_dff_time',fn.when(fn.col(\"Difference\")>0,fn.col(\"Difference\")).otherwise(fn.col(\"Difference\")+fn.lit(2400)))\n",
    "flights_df.select('new_dff_time').show(10)\n",
    "flights_df=flights_df.withColumn('Difference_Arrival',fn.col(\"SCHEDULED_ARRIVAL\")-fn.col(\"ARRIVAL_TIME\"))\n",
    "flights_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-3191f5d237ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflights_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|Difference_Arrival|\n",
      "+------------------+\n",
      "|              22.0|\n",
      "|               9.0|\n",
      "|              -5.0|\n",
      "|              49.0|\n",
      "|              61.0|\n",
      "|              -8.0|\n",
      "|              17.0|\n",
      "|              50.0|\n",
      "|              13.0|\n",
      "|              55.0|\n",
      "|              70.0|\n",
      "|              50.0|\n",
      "|               4.0|\n",
      "|              62.0|\n",
      "|              -8.0|\n",
      "|              54.0|\n",
      "|              64.0|\n",
      "|               7.0|\n",
      "|              18.0|\n",
      "|              52.0|\n",
      "|              -6.0|\n",
      "|              -1.0|\n",
      "|               1.0|\n",
      "|              12.0|\n",
      "|              63.0|\n",
      "|              11.0|\n",
      "|               3.0|\n",
      "|             -65.0|\n",
      "|              71.0|\n",
      "|              -2.0|\n",
      "|             -83.0|\n",
      "|              16.0|\n",
      "|              null|\n",
      "|             -10.0|\n",
      "|               4.0|\n",
      "|             -55.0|\n",
      "|              10.0|\n",
      "|              51.0|\n",
      "|              75.0|\n",
      "|             -51.0|\n",
      "|              73.0|\n",
      "|              -1.0|\n",
      "|              null|\n",
      "|              11.0|\n",
      "|              51.0|\n",
      "|              -4.0|\n",
      "|              76.0|\n",
      "|              12.0|\n",
      "|              49.0|\n",
      "|             -46.0|\n",
      "|             -20.0|\n",
      "|              16.0|\n",
      "|            -125.0|\n",
      "|               7.0|\n",
      "|               1.0|\n",
      "|            -169.0|\n",
      "|              -3.0|\n",
      "|               0.0|\n",
      "|               6.0|\n",
      "|              -9.0|\n",
      "|              -5.0|\n",
      "|              14.0|\n",
      "|              11.0|\n",
      "|             -11.0|\n",
      "|              11.0|\n",
      "|              10.0|\n",
      "|               0.0|\n",
      "|               4.0|\n",
      "|              null|\n",
      "|              42.0|\n",
      "|            -182.0|\n",
      "|              -2.0|\n",
      "|             -13.0|\n",
      "|            -100.0|\n",
      "|             -94.0|\n",
      "|              46.0|\n",
      "|               5.0|\n",
      "|              15.0|\n",
      "|              -3.0|\n",
      "|              -9.0|\n",
      "|              52.0|\n",
      "|              -5.0|\n",
      "|              null|\n",
      "|              -6.0|\n",
      "|              -4.0|\n",
      "|               1.0|\n",
      "|            -106.0|\n",
      "|              14.0|\n",
      "|              58.0|\n",
      "|              25.0|\n",
      "|              null|\n",
      "|             -13.0|\n",
      "|             -66.0|\n",
      "|              -3.0|\n",
      "|             -14.0|\n",
      "|              55.0|\n",
      "|              65.0|\n",
      "|             -19.0|\n",
      "|              21.0|\n",
      "|              58.0|\n",
      "+------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.select('Difference_Arrival').show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Grouped|\n",
      "+-------+\n",
      "|   Best|\n",
      "|   Good|\n",
      "|Average|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|Average|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|   Good|\n",
      "|   Best|\n",
      "|Average|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|   Good|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|Average|\n",
      "|Average|\n",
      "|   Good|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|   Good|\n",
      "|    Bad|\n",
      "|   Best|\n",
      "|Average|\n",
      "|    Bad|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|   Good|\n",
      "|    Bad|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|    Bad|\n",
      "|   Best|\n",
      "|Average|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|Average|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|    Bad|\n",
      "|    Bad|\n",
      "|   Best|\n",
      "|    Bad|\n",
      "|   Good|\n",
      "|   Good|\n",
      "|    Bad|\n",
      "|Average|\n",
      "|   Best|\n",
      "|   Good|\n",
      "|Average|\n",
      "|Average|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|    Bad|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|   Good|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|    Bad|\n",
      "|Average|\n",
      "|    Bad|\n",
      "|    Bad|\n",
      "|    Bad|\n",
      "|   Best|\n",
      "|   Good|\n",
      "|   Best|\n",
      "|Average|\n",
      "|Average|\n",
      "|   Best|\n",
      "|Average|\n",
      "|   Best|\n",
      "|Average|\n",
      "|Average|\n",
      "|   Good|\n",
      "|    Bad|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|    Bad|\n",
      "|    Bad|\n",
      "|Average|\n",
      "|    Bad|\n",
      "|   Best|\n",
      "|   Best|\n",
      "|    Bad|\n",
      "|   Best|\n",
      "|   Best|\n",
      "+-------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "flights_df=flights_df.withColumn(\"Grouped\", fn.when((fn.col('Difference_Arrival')<0)\n",
    "                                                    & (fn.col('Difference_Arrival')>-10),fn.lit('Average'))\n",
    "                                 .otherwise(fn.when(fn.col(\"Difference_Arrival\")<-10,fn.lit('Bad'))\n",
    "                                 .otherwise(fn.when((fn.col(\"Difference_Arrival\")>0) \n",
    "                                                    & (fn.col(\"Difference_Arrival\")<10),fn.lit('Good'))\n",
    "                                 .otherwise(fn.lit('Best')))))\n",
    "flights_df.select(\"Grouped\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, regexp_replace\n",
    "\n",
    "flights_df=flights_df.withColumn(\"DEPARTURE_TIME\", regexp_replace(col(\"DEPARTURE_TIME\") ,  \"(\\\\d{2})(\\\\d{2})\" , \"$1:$2\" ) )\n",
    "flights_df=flights_df.withColumn(\"ARRIVAL_TIME\", regexp_replace(col(\"ARRIVAL_TIME\") ,  \"(\\\\d{2})(\\\\d{2})\" , \"$1:$2\" ) )\n",
    "flights_df=flights_df.withColumn(\"WHEELS_OFF\", regexp_replace(col(\"WHEELS_OFF\") ,  \"(\\\\d{2})(\\\\d{2})\" , \"$1:$2\" ) )\n",
    "flights_df=flights_df.withColumn(\"WHEELS_ON\", regexp_replace(col(\"WHEELS_ON\") ,  \"(\\\\d{2})(\\\\d{2})\" , \"$1:$2\" ) )\n",
    "flights_df=flights_df.withColumn(\"SCHEDULED_DEPARTURE\", regexp_replace(col(\"SCHEDULED_DEPARTURE\") ,  \"(\\\\d{2})(\\\\d{2})\" , \"$1:$2\" ) )\n",
    "flights_df=flights_df.withColumn(\"SCHEDULED_ARRIVAL\", regexp_replace(col(\"SCHEDULED_ARRIVAL\") ,  \"(\\\\d{2})(\\\\d{2})\" , \"$1:$2\" ) )\n",
    "flights_df=flights_df.withColumn(\"new_df_time\", regexp_replace(col(\"new_dff_time\") ,  \"(\\\\d{1})(\\\\d{2})\" , \"$1:$2\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|DEPARTURE_TIME|\n",
      "+--------------+\n",
      "|         23:54|\n",
      "|         00:02|\n",
      "|         00:18|\n",
      "|         00:15|\n",
      "|         00:24|\n",
      "|         00:20|\n",
      "|         00:19|\n",
      "|         00:44|\n",
      "|         00:19|\n",
      "|         00:33|\n",
      "|         00:24|\n",
      "|         00:27|\n",
      "|         00:35|\n",
      "|         00:34|\n",
      "|         00:39|\n",
      "|         00:41|\n",
      "|         00:31|\n",
      "|         00:42|\n",
      "|         00:46|\n",
      "|         00:45|\n",
      "|         01:20|\n",
      "|         00:52|\n",
      "|         01:02|\n",
      "|         01:03|\n",
      "|         01:02|\n",
      "|         01:12|\n",
      "|         01:07|\n",
      "|         01:27|\n",
      "|         01:10|\n",
      "|         01:41|\n",
      "+--------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.select('DEPARTURE_TIME').show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df=flights_df.withColumn(\"Cal_Airtime\",fn.col(\"DEPARTURE_TIME\")-fn.col(\"ARRIVAL_TIME\"))\n",
    "flights_df=flights_df.withColumn(\"Cal_Airtime1\",fn.col(\"WHEELS_OFF\")-fn.col(\"WHEELS_ON\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|CAL_TIME|\n",
      "+--------+\n",
      "|    null|\n",
      "|    null|\n",
      "|    null|\n",
      "|    null|\n",
      "|    null|\n",
      "+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import unix_timestamp\n",
    "\n",
    "#from pyspark.sql import functions as F\n",
    "#time = F.unix_timestamp(fn.col('DEPARTURE_TIME'), format=\"HH:MM\")\n",
    "flights_df = flights_df.withColumn(\"CAL_TIME\",fn.unix_timestamp('DEPARTURE_TIME',format='HH:mm.SSS'))\n",
    "#flights_df.select(datetime.datetime.strptime('DEPARTURE_TIME', '%H%H:%M%M').time())\n",
    "#datetime.time(3, 55)\n",
    "flights_df.select(\"CAL_TIME\").show(5)\n",
    "\n",
    "#flights_df1 = flights_df.select('DEPARTURE_TIME', unix_timestamp('DEPARTURE_TIME', 'HH:MM'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------------------------+\n",
      "|DEPARTURE_TIME|unix_timestamp(DEPARTURE_TIME, HH:MM)|\n",
      "+--------------+-------------------------------------+\n",
      "|         23:54|                                 null|\n",
      "|         00:02|                              2678400|\n",
      "|         00:18|                                 null|\n",
      "|         00:15|                                 null|\n",
      "|         00:24|                                 null|\n",
      "|         00:20|                                 null|\n",
      "|         00:19|                                 null|\n",
      "|         00:44|                                 null|\n",
      "|         00:19|                                 null|\n",
      "|         00:33|                                 null|\n",
      "+--------------+-------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#flights_df1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import unix_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filtered_data=Filtered_data.withColumn(\"D_TIME\", to_timestamp(flights_df.DEPARTURE_TIME,\"hh:mm:ss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|D_TIME|\n",
      "+------+\n",
      "|  null|\n",
      "|  null|\n",
      "|  null|\n",
      "|  null|\n",
      "|  null|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Filtered_data.select(\"D_TIME\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_delta(y,x): \n",
    "    from datetime import datetime\n",
    "    end = datetime.strptime(y, '%Y-%m-%d %H:%M:%S')\n",
    "    start = datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "    delta = (end-start).total_seconds()\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, IntegerType, StructType, StructField\n",
    "f = udf(time_delta, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o734.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 98.0 failed 1 times, most recent failure: Lost task 0.0 in stage 98.0 (TID 298, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 324, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 139, in dump_stream\n    for obj in iterator:\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 313, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 75, in <lambda>\n    return lambda *a: f(*a)\n  File \"/usr/local/spark/python/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-61-53ea946be9bc>\", line 3, in time_delta\nTypeError: strptime() argument 1 must be str, not datetime.datetime\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:83)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:66)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:253)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:830)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:830)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1602)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1590)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1589)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1589)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1823)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1772)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1761)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:363)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3273)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3254)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3253)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2698)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:254)\n\tat sun.reflect.GeneratedMethodAccessor122.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 324, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 139, in dump_stream\n    for obj in iterator:\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 313, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 75, in <lambda>\n    return lambda *a: f(*a)\n  File \"/usr/local/spark/python/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-61-53ea946be9bc>\", line 3, in time_delta\nTypeError: strptime() argument 1 must be str, not datetime.datetime\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:83)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:66)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:253)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:830)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:830)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-1cdc3cbcd580>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflights_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'diff'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflights_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculated_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflights_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculated_time_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \"\"\"\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o734.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 98.0 failed 1 times, most recent failure: Lost task 0.0 in stage 98.0 (TID 298, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 324, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 139, in dump_stream\n    for obj in iterator:\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 313, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 75, in <lambda>\n    return lambda *a: f(*a)\n  File \"/usr/local/spark/python/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-61-53ea946be9bc>\", line 3, in time_delta\nTypeError: strptime() argument 1 must be str, not datetime.datetime\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:83)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:66)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:253)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:830)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:830)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1602)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1590)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1589)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1589)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1823)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1772)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1761)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:363)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3273)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3254)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3253)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2484)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2698)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:254)\n\tat sun.reflect.GeneratedMethodAccessor122.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 324, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 139, in dump_stream\n    for obj in iterator:\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 313, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 75, in <lambda>\n    return lambda *a: f(*a)\n  File \"/usr/local/spark/python/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-61-53ea946be9bc>\", line 3, in time_delta\nTypeError: strptime() argument 1 must be str, not datetime.datetime\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:83)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:66)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1.hasNext(WholeStageCodegenExec.scala:614)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:253)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:830)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:830)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "flights_df.withColumn('diff', f(flights_df.calculated_time, flights_df.calculated_time_arr)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|    calculated_time|calculated_time_arr|\n",
      "+-------------------+-------------------+\n",
      "|1970-01-01 23:54:00|1970-01-01 04:08:00|\n",
      "|1970-01-01 00:02:00|1970-01-01 07:41:00|\n",
      "+-------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.select('calculated_time','calculated_time_arr').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "strptime() argument 1 must be str, not Column",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-be46d5244d0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mflights_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'calculated_time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflights_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'calculated_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%Y-%m-%dT%H:%M:%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mflights_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'calculated_time_arr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflights_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'calculated_time_arr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%Y-%m-%dT%H:%M:%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mflights_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflights_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'diff'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'calculated_time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'calculated_time_arr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: strptime() argument 1 must be str, not Column"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "flights_df['calculated_time'] = datetime.strptime(flights_df['calculated_time'], '%Y-%m-%dT%H:%M:%S')\n",
    "flights_df['calculated_time_arr'] = datetime.strptime(flights_df['calculated_time_arr'], '%Y-%m-%dT%H:%M:%S')\n",
    "flights_df = flights_df.withColumn('diff',fn.col('calculated_time')-fn.col('calculated_time_arr')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"cannot resolve '(`calculated_time` - `calculated_time_arr`)' due to data type mismatch: '(`calculated_time` - `calculated_time_arr`)' requires (numeric or calendarinterval) type, not timestamp;;\\n'Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#4446, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#4420, TAXI_IN#3862, SCHEDULED_ARRIVAL#4472, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, ... 6 more fields]\\n+- AnalysisBarrier\\n      +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#4446, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#4420, TAXI_IN#3862, SCHEDULED_ARRIVAL#4472, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, ... 5 more fields]\\n         +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#4446, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#4420, TAXI_IN#3862, SCHEDULED_ARRIVAL#4472, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, ... 4 more fields]\\n            +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#4446, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#4420, TAXI_IN#3862, SCHEDULED_ARRIVAL#4472, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, ... 3 more fields]\\n               +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#4446, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#4420, TAXI_IN#3862, SCHEDULED_ARRIVAL#4472, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, ... 2 more fields]\\n                  +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#4446, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#4420, TAXI_IN#3862, regexp_replace(SCHEDULED_ARRIVAL#3863, (\\\\d{2})(\\\\d{2}), $1:$2) AS SCHEDULED_ARRIVAL#4472, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, CANCELLED#3867]\\n                     +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, regexp_replace(SCHEDULED_DEPARTURE#3852, (\\\\d{2})(\\\\d{2}), $1:$2) AS SCHEDULED_DEPARTURE#4446, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#4420, TAXI_IN#3862, SCHEDULED_ARRIVAL#3863, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, CANCELLED#3867]\\n                        +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#3852, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, regexp_replace(WHEELS_ON#3861, (\\\\d{2})(\\\\d{2}), $1:$2) AS WHEELS_ON#4420, TAXI_IN#3862, SCHEDULED_ARRIVAL#3863, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, CANCELLED#3867]\\n                           +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#3852, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, regexp_replace(WHEELS_OFF#3856, (\\\\d{2})(\\\\d{2}), $1:$2) AS WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#3861, TAXI_IN#3862, SCHEDULED_ARRIVAL#3863, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, CANCELLED#3867]\\n                              +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#3852, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#3856, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#3861, TAXI_IN#3862, SCHEDULED_ARRIVAL#3863, regexp_replace(ARRIVAL_TIME#3864, (\\\\d{2})(\\\\d{2}), $1:$2) AS ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, CANCELLED#3867]\\n                                 +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#3852, regexp_replace(DEPARTURE_TIME#3853, (\\\\d{2})(\\\\d{2}), $1:$2) AS DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#3856, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#3861, TAXI_IN#3862, SCHEDULED_ARRIVAL#3863, ARRIVAL_TIME#3864, ARRIVAL_DELAY#3865, DIVERTED#3866, CANCELLED#3867]\\n                                    +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#3852, DEPARTURE_TIME#3853, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#3856, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#3861, TAXI_IN#3862, SCHEDULED_ARRIVAL#3863, ARRIVAL_TIME#3864, ARRIVAL_DELAY#3865, DIVERTED#3866, CANCELLED#3867]\\n                                       +- Relation[YEAR#3843,MONTH#3844,DAY#3845,DAY_OF_WEEK#3846,AIRLINE#3847,FLIGHT_NUMBER#3848,TAIL_NUMBER#3849,ORIGIN_AIRPORT#3850,DESTINATION_AIRPORT#3851,SCHEDULED_DEPARTURE#3852,DEPARTURE_TIME#3853,DEPARTURE_DELAY#3854,TAXI_OUT#3855,WHEELS_OFF#3856,SCHEDULED_TIME#3857,ELAPSED_TIME#3858,AIR_TIME#3859,DISTANCE#3860,WHEELS_ON#3861,TAXI_IN#3862,SCHEDULED_ARRIVAL#3863,ARRIVAL_TIME#3864,ARRIVAL_DELAY#3865,DIVERTED#3866,... 7 more fields] csv\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o442.withColumn.\n: org.apache.spark.sql.AnalysisException: cannot resolve '(`calculated_time` - `calculated_time_arr`)' due to data type mismatch: '(`calculated_time` - `calculated_time_arr`)' requires (numeric or calendarinterval) type, not timestamp;;\n'Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#4446, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#4420, TAXI_IN#3862, SCHEDULED_ARRIVAL#4472, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, ... 6 more fields]\n+- AnalysisBarrier\n      +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#4446, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#4420, TAXI_IN#3862, SCHEDULED_ARRIVAL#4472, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, ... 5 more fields]\n         +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#4446, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#4420, TAXI_IN#3862, SCHEDULED_ARRIVAL#4472, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, ... 4 more fields]\n            +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#4446, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#4420, TAXI_IN#3862, SCHEDULED_ARRIVAL#4472, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, ... 3 more fields]\n               +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#4446, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#4420, TAXI_IN#3862, SCHEDULED_ARRIVAL#4472, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, ... 2 more fields]\n                  +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#4446, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#4420, TAXI_IN#3862, regexp_replace(SCHEDULED_ARRIVAL#3863, (\\d{2})(\\d{2}), $1:$2) AS SCHEDULED_ARRIVAL#4472, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, CANCELLED#3867]\n                     +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, regexp_replace(SCHEDULED_DEPARTURE#3852, (\\d{2})(\\d{2}), $1:$2) AS SCHEDULED_DEPARTURE#4446, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#4420, TAXI_IN#3862, SCHEDULED_ARRIVAL#3863, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, CANCELLED#3867]\n                        +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#3852, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, regexp_replace(WHEELS_ON#3861, (\\d{2})(\\d{2}), $1:$2) AS WHEELS_ON#4420, TAXI_IN#3862, SCHEDULED_ARRIVAL#3863, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, CANCELLED#3867]\n                           +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#3852, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, regexp_replace(WHEELS_OFF#3856, (\\d{2})(\\d{2}), $1:$2) AS WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#3861, TAXI_IN#3862, SCHEDULED_ARRIVAL#3863, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, CANCELLED#3867]\n                              +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#3852, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#3856, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#3861, TAXI_IN#3862, SCHEDULED_ARRIVAL#3863, regexp_replace(ARRIVAL_TIME#3864, (\\d{2})(\\d{2}), $1:$2) AS ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, CANCELLED#3867]\n                                 +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#3852, regexp_replace(DEPARTURE_TIME#3853, (\\d{2})(\\d{2}), $1:$2) AS DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#3856, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#3861, TAXI_IN#3862, SCHEDULED_ARRIVAL#3863, ARRIVAL_TIME#3864, ARRIVAL_DELAY#3865, DIVERTED#3866, CANCELLED#3867]\n                                    +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#3852, DEPARTURE_TIME#3853, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#3856, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#3861, TAXI_IN#3862, SCHEDULED_ARRIVAL#3863, ARRIVAL_TIME#3864, ARRIVAL_DELAY#3865, DIVERTED#3866, CANCELLED#3867]\n                                       +- Relation[YEAR#3843,MONTH#3844,DAY#3845,DAY_OF_WEEK#3846,AIRLINE#3847,FLIGHT_NUMBER#3848,TAIL_NUMBER#3849,ORIGIN_AIRPORT#3850,DESTINATION_AIRPORT#3851,SCHEDULED_DEPARTURE#3852,DEPARTURE_TIME#3853,DEPARTURE_DELAY#3854,TAXI_OUT#3855,WHEELS_OFF#3856,SCHEDULED_TIME#3857,ELAPSED_TIME#3858,AIR_TIME#3859,DISTANCE#3860,WHEELS_ON#3861,TAXI_IN#3862,SCHEDULED_ARRIVAL#3863,ARRIVAL_TIME#3864,ARRIVAL_DELAY#3865,DIVERTED#3866,... 7 more fields] csv\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:93)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:289)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:289)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:288)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:286)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:286)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:286)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:95)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:95)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:107)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:107)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:118)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$1.apply(QueryPlan.scala:122)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.foreach(List.scala:381)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.map(List.scala:285)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:122)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:127)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:127)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:95)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:85)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:80)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:80)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:92)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:74)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:3296)\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1307)\n\tat org.apache.spark.sql.Dataset.withColumns(Dataset.scala:2192)\n\tat org.apache.spark.sql.Dataset.withColumn(Dataset.scala:2159)\n\tat sun.reflect.GeneratedMethodAccessor114.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-e493508d2687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mflights_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflights_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'calculated_time_arr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mto_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflights_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mARRIVAL_TIME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HH:mm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#flights_df = flights_df.withColumn('new_calculated_time',flights_df['calculated_time'].split()[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mflights_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflights_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sub_col'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'calculated_time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'calculated_time_arr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \"\"\"\n\u001b[1;32m   1848\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1849\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"cannot resolve '(`calculated_time` - `calculated_time_arr`)' due to data type mismatch: '(`calculated_time` - `calculated_time_arr`)' requires (numeric or calendarinterval) type, not timestamp;;\\n'Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#4446, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#4420, TAXI_IN#3862, SCHEDULED_ARRIVAL#4472, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, ... 6 more fields]\\n+- AnalysisBarrier\\n      +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#4446, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#4420, TAXI_IN#3862, SCHEDULED_ARRIVAL#4472, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, ... 5 more fields]\\n         +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#4446, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#4420, TAXI_IN#3862, SCHEDULED_ARRIVAL#4472, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, ... 4 more fields]\\n            +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#4446, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#4420, TAXI_IN#3862, SCHEDULED_ARRIVAL#4472, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, ... 3 more fields]\\n               +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#4446, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#4420, TAXI_IN#3862, SCHEDULED_ARRIVAL#4472, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, ... 2 more fields]\\n                  +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#4446, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#4420, TAXI_IN#3862, regexp_replace(SCHEDULED_ARRIVAL#3863, (\\\\d{2})(\\\\d{2}), $1:$2) AS SCHEDULED_ARRIVAL#4472, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, CANCELLED#3867]\\n                     +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, regexp_replace(SCHEDULED_DEPARTURE#3852, (\\\\d{2})(\\\\d{2}), $1:$2) AS SCHEDULED_DEPARTURE#4446, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#4420, TAXI_IN#3862, SCHEDULED_ARRIVAL#3863, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, CANCELLED#3867]\\n                        +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#3852, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, regexp_replace(WHEELS_ON#3861, (\\\\d{2})(\\\\d{2}), $1:$2) AS WHEELS_ON#4420, TAXI_IN#3862, SCHEDULED_ARRIVAL#3863, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, CANCELLED#3867]\\n                           +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#3852, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, regexp_replace(WHEELS_OFF#3856, (\\\\d{2})(\\\\d{2}), $1:$2) AS WHEELS_OFF#4394, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#3861, TAXI_IN#3862, SCHEDULED_ARRIVAL#3863, ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, CANCELLED#3867]\\n                              +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#3852, DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#3856, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#3861, TAXI_IN#3862, SCHEDULED_ARRIVAL#3863, regexp_replace(ARRIVAL_TIME#3864, (\\\\d{2})(\\\\d{2}), $1:$2) AS ARRIVAL_TIME#4368, ARRIVAL_DELAY#3865, DIVERTED#3866, CANCELLED#3867]\\n                                 +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#3852, regexp_replace(DEPARTURE_TIME#3853, (\\\\d{2})(\\\\d{2}), $1:$2) AS DEPARTURE_TIME#4342, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#3856, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#3861, TAXI_IN#3862, SCHEDULED_ARRIVAL#3863, ARRIVAL_TIME#3864, ARRIVAL_DELAY#3865, DIVERTED#3866, CANCELLED#3867]\\n                                    +- Project [YEAR#3843, MONTH#3844, DAY#3845, DAY_OF_WEEK#3846, AIRLINE#3847, FLIGHT_NUMBER#3848, TAIL_NUMBER#3849, ORIGIN_AIRPORT#3850, DESTINATION_AIRPORT#3851, SCHEDULED_DEPARTURE#3852, DEPARTURE_TIME#3853, DEPARTURE_DELAY#3854, TAXI_OUT#3855, WHEELS_OFF#3856, SCHEDULED_TIME#3857, ELAPSED_TIME#3858, AIR_TIME#3859, DISTANCE#3860, WHEELS_ON#3861, TAXI_IN#3862, SCHEDULED_ARRIVAL#3863, ARRIVAL_TIME#3864, ARRIVAL_DELAY#3865, DIVERTED#3866, CANCELLED#3867]\\n                                       +- Relation[YEAR#3843,MONTH#3844,DAY#3845,DAY_OF_WEEK#3846,AIRLINE#3847,FLIGHT_NUMBER#3848,TAIL_NUMBER#3849,ORIGIN_AIRPORT#3850,DESTINATION_AIRPORT#3851,SCHEDULED_DEPARTURE#3852,DEPARTURE_TIME#3853,DEPARTURE_DELAY#3854,TAXI_OUT#3855,WHEELS_OFF#3856,SCHEDULED_TIME#3857,ELAPSED_TIME#3858,AIR_TIME#3859,DISTANCE#3860,WHEELS_ON#3861,TAXI_IN#3862,SCHEDULED_ARRIVAL#3863,ARRIVAL_TIME#3864,ARRIVAL_DELAY#3865,DIVERTED#3866,... 7 more fields] csv\\n\""
     ]
    }
   ],
   "source": [
    "flights_df = flights_df.withColumn('calculated_time',to_timestamp(flights_df.DEPARTURE_TIME, 'HH:mm'))\n",
    "flights_df = flights_df.withColumn('calculated_time_arr',to_timestamp(flights_df.ARRIVAL_TIME, 'HH:mm'))\n",
    "#flights_df = flights_df.withColumn('new_calculated_time',flights_df['calculated_time'].split()[1])\n",
    "flights_df=flights_df.withColumn('Sub_col',fn.col('calculated_time')-fn.col('calculated_time_arr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|D_TIME|\n",
      "+------+\n",
      "|  null|\n",
      "|  null|\n",
      "|  null|\n",
      "|  null|\n",
      "|  null|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "flights_df.select(to_timestamp(flights_df.DEPARTURE_TIME, 'HHmm').alias('D_TIME')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|D_TIME|\n",
      "+------+\n",
      "|  null|\n",
      "|  null|\n",
      "|  null|\n",
      "|  null|\n",
      "|  null|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.select(\"D_TIME\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------+--------------+-----------------+------------+--------+---------+----------+------------+\n",
      "|SCHEDULED_DEPARTURE|DEPARTURE_DELAY|DEPARTURE_TIME|SCHEDULED_ARRIVAL|ARRIVAL_TIME|AIR_TIME|WHEELS_ON|WHEELS_OFF|new_dff_time|\n",
      "+-------------------+---------------+--------------+-----------------+------------+--------+---------+----------+------------+\n",
      "|              00:05|            -11|         23:54|            04:30|       04:08|     169|    04:04|     00:15|       454.0|\n",
      "|              00:10|             -8|         00:02|            07:50|       07:41|     263|    07:37|     00:14|       739.0|\n",
      "|              00:20|             -2|         00:18|            08:06|       08:11|     266|    08:00|     00:34|       793.0|\n",
      "|              00:20|             -5|         00:15|            08:05|       07:56|     258|    07:48|     00:30|       741.0|\n",
      "|              00:25|             -1|         00:24|            03:20|       02:59|     199|    02:54|     00:35|       235.0|\n",
      "|              00:25|             -5|         00:20|            06:02|       06:10|     206|    06:04|     00:38|       590.0|\n",
      "|              00:25|             -6|         00:19|            05:26|       05:09|     154|    05:04|     00:30|       490.0|\n",
      "|              00:30|             14|         00:44|            08:03|       07:53|     228|    07:45|     00:57|       709.0|\n",
      "|              00:30|            -11|         00:19|            05:45|       05:32|     173|    05:29|     00:36|       513.0|\n",
      "|              00:30|              3|         00:33|            07:11|       06:56|     186|    06:51|     00:45|       623.0|\n",
      "|              00:30|             -6|         00:24|            05:23|       04:53|     133|    04:49|     00:36|       429.0|\n",
      "|              00:35|             -8|         00:27|            08:03|       07:53|     238|    07:46|     00:48|       726.0|\n",
      "|              00:35|              0|         00:35|            06:09|       06:05|     188|    06:01|     00:53|       570.0|\n",
      "|              00:40|             -6|         00:34|            06:15|       05:53|     176|    05:48|     00:52|       519.0|\n",
      "|              00:40|             -1|         00:39|            05:49|       05:57|     166|    05:53|     01:07|       518.0|\n",
      "|              00:45|             -4|         00:41|            05:09|       04:55|     173|    04:51|     00:58|       414.0|\n",
      "|              00:45|            -14|         00:31|            05:15|       04:51|     171|    04:47|     00:56|       420.0|\n",
      "|              00:48|             -6|         00:42|            06:26|       06:19|     199|    06:12|     00:53|       577.0|\n",
      "|              00:50|             -4|         00:46|            05:25|       05:07|     187|    05:04|     00:57|       461.0|\n",
      "|              00:50|             -5|         00:45|            06:03|       05:51|     171|    05:45|     00:54|       506.0|\n",
      "|              00:55|             25|         01:20|            05:37|       05:43|     128|    05:39|     01:31|       423.0|\n",
      "|              01:00|             -8|         00:52|            09:38|       09:39|     311|    09:33|     01:22|       887.0|\n",
      "|              01:03|             -1|         01:02|            05:30|       05:29|     128|    05:23|     01:15|       427.0|\n",
      "|              01:05|             -2|         01:03|            08:51|       08:39|     255|    08:32|     01:17|       736.0|\n",
      "|              01:05|             -3|         01:02|            06:08|       05:45|     150|    05:43|     01:13|       443.0|\n",
      "|              01:15|             -3|         01:12|            06:18|       06:07|     156|    05:59|     01:23|       495.0|\n",
      "|              01:15|             -8|         01:07|            05:48|       05:45|     186|    05:38|     01:32|       438.0|\n",
      "|              01:15|             12|         01:27|            05:42|       06:07|     166|    05:27|     01:41|       480.0|\n",
      "|              01:20|            -10|         01:10|            08:25|       07:54|     205|    07:47|     01:22|       644.0|\n",
      "|              01:20|             21|         01:41|            07:07|       07:09|     188|    07:01|     01:53|       568.0|\n",
      "|              01:25|             72|         02:37|            05:49|       06:32|     156|    06:22|     02:46|       395.0|\n",
      "|              01:27|            -11|         01:16|            07:26|       07:10|     217|    07:03|     01:26|       594.0|\n",
      "|              01:35|           null|          null|            06:00|        null|    null|     null|      null|        null|\n",
      "|              01:40|             -6|         01:34|            07:15|       07:25|     182|    07:19|     02:17|       591.0|\n",
      "|              01:44|             -4|         01:40|            06:34|       06:30|     148|    06:18|     01:50|       490.0|\n",
      "|              01:45|              0|         01:45|            05:55|       06:10|     361|    06:02|     02:01|       465.0|\n",
      "|              01:52|             -9|         01:43|            09:15|       09:05|     298|    09:02|     02:04|       762.0|\n",
      "|              01:54|              3|         01:57|            05:09|       04:58|     220|    04:49|     02:09|       301.0|\n",
      "|              01:55|            -15|         01:40|            06:33|       05:58|     170|    05:47|     01:57|       418.0|\n",
      "|              01:55|             -2|         01:53|            04:50|       05:01|     231|    04:56|     02:05|       348.0|\n",
      "|              01:55|            -16|         01:39|            05:23|       04:50|     174|    04:43|     01:49|       311.0|\n",
      "|              01:59|             -1|         01:58|            05:02|       05:03|     103|    04:52|     02:09|       345.0|\n",
      "|              02:00|           null|          null|            05:00|        null|    null|     null|      null|        null|\n",
      "|              02:00|            -10|         01:50|            06:30|       06:19|     182|    06:16|     02:14|       469.0|\n",
      "|              02:00|             -5|         01:55|            05:04|       04:53|     149|    04:45|     02:16|       298.0|\n",
      "|              02:06|            -14|         01:52|            05:12|       05:16|     239|    05:10|     02:11|       364.0|\n",
      "|              02:20|            -11|         02:09|            08:04|       07:28|     183|    07:22|     02:19|       519.0|\n",
      "|              02:20|            -11|         02:09|            06:40|       06:28|     176|    06:20|     02:24|       419.0|\n",
      "|              02:55|             -7|         02:48|            05:00|       04:51|     169|    04:47|     02:58|       203.0|\n",
      "|              02:59|             -1|         02:58|            05:59|       06:05|     225|    05:57|     03:12|       347.0|\n",
      "|              03:07|             -3|         03:04|            05:00|       05:20|     160|    05:09|     03:29|       216.0|\n",
      "|              03:30|            -14|         03:16|            06:35|       06:19|     224|    06:14|     03:30|       303.0|\n",
      "|              04:00|             95|         05:35|            06:05|       07:30|     163|    07:27|     05:44|       195.0|\n",
      "|              04:19|              4|         04:23|            06:13|       06:06|     148|    06:02|     04:34|       183.0|\n",
      "|              04:24|            -11|         04:13|            06:30|       06:29|     166|    06:23|     04:37|       216.0|\n",
      "|              04:38|             72|         05:50|            07:39|       09:08|     237|    09:02|     06:05|       358.0|\n",
      "|              05:00|             -1|         04:59|            07:48|       07:51|     214|    07:45|     05:11|       292.0|\n",
      "|              05:00|             -4|         04:56|            06:10|       06:10|      39|    05:57|     05:18|       154.0|\n",
      "|              05:00|             -8|         04:52|            05:49|       05:43|      35|    05:37|     05:02|        91.0|\n",
      "|              05:00|             13|         05:13|            06:29|       06:38|      61|    06:33|     05:32|       125.0|\n",
      "|              05:02|             -1|         05:01|            05:44|       05:49|      30|    05:43|     05:13|        48.0|\n",
      "|              05:05|             -8|         04:57|            09:30|       09:16|     179|    09:12|     05:13|       459.0|\n",
      "|              05:05|            -11|         04:54|            05:41|       05:30|      20|    05:24|     05:04|        76.0|\n",
      "|              05:10|              4|         05:14|            08:05|       08:16|     147|    08:04|     05:37|       302.0|\n",
      "|              05:10|             -3|         05:07|            06:13|       06:02|      38|    05:59|     05:21|        95.0|\n",
      "|              05:10|             -4|         05:06|            07:30|       07:20|     112|    07:14|     05:22|       214.0|\n",
      "|              05:10|            -10|         05:00|            06:18|       06:18|      35|    06:12|     05:37|       118.0|\n",
      "|              05:10|             -2|         05:08|            06:19|       06:15|      41|    06:10|     05:29|       107.0|\n",
      "|              05:10|           null|          null|            06:37|        null|    null|     null|      null|        null|\n",
      "|              05:15|             -5|         05:10|            09:00|       08:58|     146|    08:51|     05:25|       348.0|\n",
      "|              05:15|            108|         07:03|            08:56|       10:38|     133|    10:31|     07:18|       335.0|\n",
      "|              05:15|             -5|         05:10|            08:43|       08:45|     182|    08:26|     05:24|       335.0|\n",
      "|              05:15|              2|         05:17|            08:13|       08:26|     163|    08:12|     05:29|       309.0|\n",
      "|              05:20|             60|         06:20|            08:50|       09:50|     132|    09:45|     06:33|       330.0|\n",
      "|              05:20|             58|         06:18|            08:41|       09:35|     111|    09:28|     06:37|       317.0|\n",
      "|              05:20|             -9|         05:11|            08:03|       07:57|      66|    07:47|     05:41|       246.0|\n",
      "|              05:20|             -3|         05:17|            06:34|       06:29|      49|    06:21|     05:32|       112.0|\n",
      "|              05:20|             -6|         05:14|            07:26|       07:11|      42|    07:05|     05:23|       197.0|\n",
      "|              05:20|              5|         05:25|            06:12|       06:15|      79|    06:08|     05:49|        90.0|\n",
      "|              05:20|             -3|         05:17|            06:20|       06:29|      34|    06:22|     05:48|       112.0|\n",
      "|              05:23|            -10|         05:13|            06:00|       05:48|      21|    05:41|     05:20|        35.0|\n",
      "|              05:25|              0|         05:25|            07:30|       07:35|      35|    07:32|     05:57|       210.0|\n",
      "|              05:25|           null|          null|            07:00|        null|    null|     null|      null|        null|\n",
      "|              05:30|              2|         05:32|            08:20|       08:26|     210|    08:14|     05:44|       294.0|\n",
      "|              05:30|              4|         05:34|            08:52|       08:56|     125|    08:48|     05:43|       322.0|\n",
      "|              05:30|             -1|         05:29|            09:07|       09:06|     138|    08:57|     05:39|       377.0|\n",
      "|              05:30|             53|         06:23|            08:35|       09:41|      96|    09:31|     06:55|       318.0|\n",
      "|              05:30|             -3|         05:27|            05:25|       05:11|      22|    05:01|     05:39|      2384.0|\n",
      "|              05:30|             -4|         05:26|            08:10|       07:52|     128|    07:46|     05:38|       226.0|\n",
      "|              05:30|             -4|         05:26|            09:38|       09:13|     149|    09:07|     05:38|       387.0|\n",
      "|              05:30|           null|          null|            07:00|        null|    null|     null|      null|        null|\n",
      "|              05:30|             -4|         05:26|            09:13|       09:26|     143|    09:15|     05:52|       400.0|\n",
      "|              05:31|             19|         05:50|            08:57|       09:23|     127|    09:12|     06:05|       373.0|\n",
      "|              05:33|              7|         05:40|            07:20|       07:23|     142|    07:12|     05:50|       183.0|\n",
      "|              05:35|              6|         05:41|            08:02|       08:16|     194|    08:07|     05:53|       275.0|\n",
      "|              05:35|             -5|         05:30|            07:03|       06:48|      56|    06:43|     05:47|       118.0|\n",
      "|              05:35|             -7|         05:28|            07:00|       06:35|      50|    06:31|     05:41|       107.0|\n",
      "|              05:35|             43|         06:18|            10:20|       10:39|     184|    10:35|     06:31|       421.0|\n",
      "|              05:35|            -12|         05:23|            06:36|       06:15|      33|    06:08|     05:35|        92.0|\n",
      "|              05:35|             -5|         05:30|            08:03|       07:45|      54|    07:42|     05:48|       215.0|\n",
      "+-------------------+---------------+--------------+-----------------+------------+--------+---------+----------+------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.select('SCHEDULED_DEPARTURE','DEPARTURE_DELAY','DEPARTURE_TIME','SCHEDULED_ARRIVAL','ARRIVAL_TIME','AIR_TIME','WHEELS_ON','WHEELS_OFF',\"new_dff_time\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
